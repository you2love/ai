<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>RAG从入门到精通 - AI技术学习平台</title>
    <link rel="stylesheet" href="css/styles.css">
    <!-- Prism.js syntax highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
</head>
<body>
    <section class="section">
        <div class="container">
            <h2 class="section-title">📚 RAG从入门到精通</h2>
            <p class="section-subtitle">检索增强生成完整指南</p>

            <!-- RAG概述 -->
            <div class="card" style="margin-bottom: 2rem;">
                <div class="card-header">
                    <div class="card-icon">📚</div>
                    <div>
                        <div class="card-title">什么是RAG？</div>
                        <div class="card-subtitle">Retrieval-Augmented Generation</div>
                    </div>
                </div>
                <div class="card-body">
                    <!-- 新增文字解释 -->
                    <div style="margin-bottom: 1.5rem; line-height: 1.6;">
                        <p><strong>RAG = Retrieval-Augmented Generation（检索增强生成）</strong>，一句话概括：先从知识库里"找资料"，再让 LLM 结合这些资料生成回答。</p>
                        <p>典型流程：用户提问 → 系统把问题转成向量 → 在向量数据库里检索相似文档块 → 把"问题 + 相关文档"一起丢给 LLM → LLM 基于资料生成答案。</p>
                        <p>价值在于：1) LLM 的"记忆"有限（上下文长度有限，知识可能过时）；2) RAG 能把企业/私有知识库"外挂"给 LLM，不需要重新训练模型；3) 目前企业落地大模型，RAG 是最主流、最可控的方案。</p>
                    </div>
                    
                    <div class="diagram-box">
                        <div class="diagram-title">为什么需要RAG？</div>
                        <div class="diagram-content">
┌─────────────────────────────────────────────────────────────────┐
│                                                                 │
│  RAG = 检索 + 生成，让AI基于知识库回答问题                       │
│                                                                 │
│  ┌──────────────┐    ┌──────────────────┐    ┌──────────────┐  │
│  │   用户问题   │───▶│   检索相关文档   │───▶│   LLM生成   │  │
│  └──────────────┘    └──────────────────┘    └──────────────┘  │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
                        </div>
                    </div>

                    <div class="table-container" style="margin-top: 1rem;">
                        <table>
                            <thead>
                                <tr>
                                    <th>问题</th>
                                    <th>传统LLM</th>
                                    <th>RAG</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr><td>知识时效性</td><td>固定</td><td>动态更新</td></tr>
                                <tr><td>幻觉问题</td><td>可能产生</td><td>基于事实</td></tr>
                                <tr><td>私有数据</td><td>无法访问</td><td>可集成</td></tr>
                                <tr><td>答案来源</td><td>不可追溯</td><td>可引用</td></tr>
                            </tbody>
                        </table>
                    </div>
                </div>
            </div>

            <!-- RAG流程 -->
            <h3 style="margin: 2rem 0 1rem; font-size: 1.3rem;">🔄 RAG完整流程</h3>

            <div class="flow-horizontal">
                <div class="flow-h-item start">文档加载</div>
                <div class="flow-h-arrow">→</div>
                <div class="flow-h-item">文本分块</div>
                <div class="flow-h-arrow">→</div>
                <div class="flow-h-item">向量嵌入</div>
                <div class="flow-h-arrow">→</div>
                <div class="flow-h-item">存入向量库</div>
                <div class="flow-h-arrow">→</div>
                <div class="flow-h-item">检索匹配</div>
                <div class="flow-h-arrow">→</div>
                <div class="flow-h-item end">LLM生成</div>
            </div>

            <!-- 新增详细工作流说明 -->
            <div style="margin-top: 1.5rem; padding: 1rem; background: #f8f9fa; border-radius: 8px;">
                <h4 style="margin-bottom: 0.75rem;">📋 RAG 完整工作流（程序员视角）</h4>
                <div style="display: grid; grid-template-columns: 1fr 1fr 1fr; gap: 1rem;">
                    <div>
                        <h5 style="color: #2c5282; margin-bottom: 0.5rem;">1. 数据准备阶段</h5>
                        <ul style="font-size: 0.85rem; padding-left: 1.2rem;">
                            <li>加载文档（PDF、HTML、Markdown、数据库、API）</li>
                            <li>文档切分成 nodes/chunks</li>
                            <li>每个 chunk 通过 Embedding 模型转为向量</li>
                            <li>将 chunk_id, text, vector, metadata 写入向量数据库</li>
                        </ul>
                    </div>
                    <div>
                        <h5 style="color: #2c5282; margin-bottom: 0.5rem;">2. 在线服务阶段</h5>
                        <ul style="font-size: 0.85rem; padding-left: 1.2rem;">
                            <li>用户问题 → 文本 → Embedding</li>
                            <li>在向量数据库中做相似度检索，取出 top_k 个相关 chunk</li>
                            <li>把这些 chunk 拼成提示词模板发给 LLM</li>
                            <li>LLM 生成最终答案</li>
                        </ul>
                    </div>
                    <div>
                        <h5 style="color: #2c5282; margin-bottom: 0.5rem;">3. 优化方向</h5>
                        <ul style="font-size: 0.85rem; padding-left: 1.2rem;">
                            <li>切分策略优化：chunk 大小、重叠、边界</li>
                            <li>检索策略：混合检索（关键词 + 向量）、重排、过滤</li>
                            <li>上下文压缩：对检索结果做摘要或抽取，减少噪音</li>
                            <li>多轮对话：历史对话也作为上下文参与检索</li>
                        </ul>
                    </div>
                </div>
            </div>

            <!-- 核心组件 -->
            <h3 style="margin: 2rem 0 1rem; font-size: 1.3rem;">🧩 核心组件</h3>

            <div class="cards-grid">
                <div class="card">
                    <h4 style="margin-bottom: 0.75rem;">📄 文档加载器</h4>
                    <p style="font-size:0.85rem; color:#666;">PDFLoader, TextLoader, DocxLoader</p>
                </div>
                <div class="card">
                    <h4 style="margin-bottom: 0.75rem;">✂️ 文本分割器</h4>
                    <p style="font-size:0.85rem; color:#666;">RecursiveCharacterTextSplitter</p>
                </div>
                <div class="card">
                    <h4 style="margin-bottom: 0.75rem;">📐 向量嵌入</h4>
                    <p style="font-size:0.85rem; color:#666;">OpenAIEmbeddings, HuggingFaceEmbeddings</p>
                </div>
                <div class="card">
                    <h4 style="margin-bottom: 0.75rem;">🗄️ 向量数据库</h4>
                    <p style="font-size:0.85rem; color:#666;">FAISS, Chroma, Milvus, Pinecone</p>
                </div>
                <div class="card">
                    <h4 style="margin-bottom: 0.75rem;">🔍 检索器</h4>
                    <p style="font-size:0.85rem; color:#666;">相似度检索, MMR, 混合检索</p>
                </div>
                <div class="card">
                    <h4 style="margin-bottom: 0.75rem;">🤖 LLM</h4>
                    <p style="font-size:0.85rem; color:#666;">GPT-4, Claude, 开源模型</p>
                </div>
            </div>

            <!-- 新增核心三要素详解 -->
            <h3 style="margin: 2rem 0 1rem; font-size: 1.3rem;">🔧 核心三要素详解</h3>
            <div class="cards-grid">
                <div class="card">
                    <h4 style="margin-bottom: 0.75rem;">📄 文档切分（Chunking）</h4>
                    <p style="font-size: 0.85rem; color: #666; margin-bottom: 0.5rem;">
                        <strong>为什么需要切分？</strong> 文档太长会超出上下文窗口，检索时太粗粒度会带进大量无关噪音。
                    </p>
                    <ul style="font-size: 0.85rem; padding-left: 1.2rem;">
                        <li><strong>固定长度切分：</strong>按字符/Token 数切，比如 512/1024 token 一块</li>
                        <li><strong>按语义结构切：</strong>按段落、章节、HTML 结构、Markdown 标题层级切</li>
                        <li><strong>滑动窗口：</strong>chunk 之间有重叠，避免关键信息被切在边界外</li>
                    </ul>
                    <div style="margin-top: 0.75rem; padding: 0.5rem; background: #f0f7ff; border-radius: 4px;">
                        <strong>程序员要掌握：</strong>根据文档类型选择切分策略，保留元数据（文件名、页码、章节等）方便过滤和溯源。
                    </div>
                </div>
                
                <div class="card">
                    <h4 style="margin-bottom: 0.75rem;">📐 Embedding（向量化表示）</h4>
                    <p style="font-size: 0.85rem; color: #666; margin-bottom: 0.5rem;">
                        <strong>Embedding 是把文本变成向量</strong>，让计算机能衡量\"语义相似度\"。
                    </p>
                    <ul style="font-size: 0.85rem; padding-left: 1.2rem;">
                        <li>同义句在向量空间距离近，不同主题的句子距离远</li>
                        <li>使用 OpenAI text-embedding-3、bge、m3e 等模型</li>
                        <li>问题本身也被同样模型 Embedding，再去向量库里找最近邻</li>
                    </ul>
                    <div style="margin-top: 0.75rem; padding: 0.5rem; background: #f0f7ff; border-radius: 4px;">
                        <strong>程序员要掌握：</strong>不同 Embedding 模型的特点（多语言支持、长文本支持、维度大小），成本与性能权衡。
                    </div>
                </div>
                
                <div class="card">
                    <h4 style="margin-bottom: 0.75rem;">🗄️ 向量数据库（Vector Store）</h4>
                    <p style="font-size: 0.85rem; color: #666; margin-bottom: 0.5rem;">
                        <strong>专门存\"文本 + 向量\"的数据库</strong>，支持高效的向量相似度检索。
                    </p>
                    <ul style="font-size: 0.85rem; padding-left: 1.2rem;">
                        <li><strong>常见产品：</strong>Pinecone、Weaviate、Qdrant、Milvus、Chroma、pgvector</li>
                        <li><strong>核心能力：</strong>插入、查询、过滤</li>
                        <li><strong>检索参数：</strong>top_k、距离度量（cosine/dot product/l2）、阈值设定</li>
                    </ul>
                    <div style="margin-top: 0.75rem; padding: 0.5rem; background: #f0f7ff; border-radius: 4px;">
                        <strong>程序员要掌握：</strong>如何选型（云托管 vs 自托管、QPS、延迟、成本），如何设计集合/索引。
                    </div>
                </div>
            </div>

            <!-- 向量数据库对比 -->
            <h3 style="margin: 2rem 0 1rem; font-size: 1.3rem;">🗄️ 向量数据库对比</h3>

            <div class="table-container">
                <table>
                    <thead>
                        <tr>
                            <th>数据库</th>
                            <th>部署方式</th>
                            <th>规模</th>
                            <th>特点</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr><td><strong>FAISS</strong></td><td>本地</td><td>中小</td><td>免费、快速</td></tr>
                        <tr><td><strong>Chroma</strong></td><td>本地/云</td><td>中小</td><td>轻量、易用</td></tr>
                        <tr><td><strong>Milvus</strong></td><td>本地/云</td><td>大</td><td>分布式、高性能</td></tr>
                        <tr><td><strong>Pinecone</strong></td><td>云服务</td><td>超大</td><td>全托管</td></tr>
                        <tr><td><strong>Qdrant</strong></td><td>本地/云</td><td>大</td><td>Rust、高性能</td></tr>
                        <tr><td><strong>Weaviate</strong></td><td>本地/云</td><td>大</td><td>GraphQL接口、模块化</td></tr>
                        <tr><td><strong>pgvector</strong></td><td>PostgreSQL扩展</td><td>中小</td><td>与现有PostgreSQL集成</td></tr>
                    </tbody>
                </table>
            </div>

            <!-- 检索策略 -->
            <h3 style="margin: 2rem 0 1rem; font-size: 1.3rem;">🔍 检索策略</h3>

            <div class="cards-grid">
                <div class="card">
                    <h4 style="margin-bottom: 1rem;">基本检索</h4>
                    <ul style="font-size:0.9rem; padding-left:1.2rem;">
                        <li><strong>相似度检索</strong> - 余弦相似度匹配</li>
                        <li><strong>MMR</strong> - 多样性检索</li>
                        <li><strong>阈值过滤</strong> - 过滤低相似度结果</li>
                    </ul>
                </div>
                <div class="card">
                    <h4 style="margin-bottom: 1rem;">高级检索</h4>
                    <ul style="font-size:0.9rem; padding-left:1.2rem;">
                        <li><strong>混合检索</strong> - 向量+关键词</li>
                        <li><strong>重排序</strong> - 二次排序优化</li>
                        <li><strong>层级检索</strong> - 文档→段落→句子</li>
                    </ul>
                </div>
            </div>

            <!-- RAG模式 -->
            <h3 style="margin: 2rem 0 1rem; font-size: 1.3rem;">📋 RAG模式</h3>

            <div class="table-container">
                <table>
                    <thead>
                        <tr>
                            <th>模式</th>
                            <th>复杂度</th>
                            <th>适用场景</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr><td><strong>Naive RAG</strong></td><td>⭐</td><td>简单问答</td></tr>
                        <tr><td><strong>Retrieval-Read</strong></td><td>⭐⭐</td><td>标准RAG流程</td></tr>
                        <tr><td><strong>HyDE</strong></td><td>⭐⭐</td><td>假设文档增强</td></tr>
                        <tr><td><strong>RRF</strong></td><td>⭐⭐⭐</td><td>多检索器融合</td></tr>
                        <tr><td><strong>Agentic RAG</strong></td><td>⭐⭐⭐⭐</td><td>智能路由</td></tr>
                    </tbody>
                </table>
            </div>

            <!-- 评估指标 -->
            <h3 style="margin: 2rem 0 1rem; font-size: 1.3rem;">📏 评估指标</h3>

            <div class="cards-grid">
                <div class="card">
                    <h4 style="margin-bottom: 1rem;">检索质量</h4>
                    <ul style="font-size:0.9rem; padding-left:1.2rem;">
                        <li>Hit Rate - 命中率：Hit Rate@k = (# queries with relevant doc in top k) / (total queries)</li>
                        <li>MRR - 平均倒数排名：MRR = (1/|Q|) × Σ (1/rank_i)</li>
                        <li>NDCG - 归一化折损累计增益：NDCG@k = DCG@k / IDCG@k，其中 DCG@k = Σ (rel_i / log₂(i+1))</li>
                    </ul>
                </div>
                <div class="card">
                    <h4 style="margin-bottom: 1rem;">生成质量</h4>
                    <ul style="font-size:0.9rem; padding-left:1.2rem;">
                        <li>Faithfulness - 忠实度：基于人工评估或LLM评分，衡量生成内容与源文档的一致性</li>
                        <li>Answer Relevancy - 相关性：基于人工评估或LLM评分，衡量回答与问题的相关程度</li>
                        <li>Context Precision - 上下文精确度：基于人工评估或LLM评分，衡量检索上下文与问题的精确匹配程度</li>
                    </ul>
                </div>
            </div>

            <!-- 优化技巧 -->
            <h3 style="margin: 2rem 0 1rem; font-size: 1.3rem;">⚡ 优化技巧</h3>

            <div class="table-container">
                <table>
                    <thead>
                        <tr>
                            <th>问题</th>
                            <th>解决方案</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr><td><strong>检索不准确</strong></td><td>调整chunk_size、重排序、使用混合检索</td></tr>
                        <tr><td><strong>上下文过长</strong></td><td>摘要压缩、选择性检索</td></tr>
                        <tr><td><strong>幻觉回答</strong></td><td>增强提示、引用来源</td></tr>
                        <tr><td><strong>速度慢</strong></td><td>缓存、异步处理、向量压缩</td></tr>
                        <tr><td><strong>切分不理想</strong></td><td>调整chunk大小、重叠、边界，按语义结构切分</td></tr>
                        <tr><td><strong>检索噪音多</strong></td><td>使用重排序、上下文压缩、元数据过滤</td></tr>
                        <tr><td><strong>多轮对话效果差</strong></td><td>将历史对话作为上下文参与检索</td></tr>
                    </tbody>
                </table>
            </div>

            <!-- 新增程序员学习重点 -->
            <h3 style="margin: 2rem 0 1rem; font-size: 1.3rem;">🎯 程序员需要重点掌握什么？</h3>
            <div class="cards-grid">
                <div class="card">
                    <h4 style="margin-bottom: 0.75rem;">🗄️ 向量数据库的使用</h4>
                    <p style="font-size: 0.85rem; color: #666;">
                        至少会用一两个（如 Chroma / Qdrant / pgvector），掌握插入、查询、过滤等核心操作。
                    </p>
                </div>
                <div class="card">
                    <h4 style="margin-bottom: 0.75rem;">📐 Embedding 流程</h4>
                    <p style="font-size: 0.85rem; color: #666;">
                        如何调用模型、缓存向量、批量处理，了解不同 Embedding 模型的特点和成本。
                    </p>
                </div>
                <div class="card">
                    <h4 style="margin-bottom: 0.75rem;">✂️ 文档切分与预处理</h4>
                    <p style="font-size: 0.85rem; color: #666;">
                        对不同数据源设计合理的 ETL 流程，根据文档类型选择切分策略。
                    </p>
                </div>
                <div class="card">
                    <h4 style="margin-bottom: 0.75rem;">🛠️ LangChain / LlamaIndex 抽象</h4>
                    <p style="font-size: 0.85rem; color: #666;">
                        掌握 LlamaIndex 的 VectorStoreIndex、Node、Reader 概念，以及 LangChain 的 VectorStore、Retriever、Document 抽象。
                    </p>
                </div>
            </div>

            <h3>💻 代码示例</h3>

            <div class="card">
                <div class="card-header">示例：完整RAG系统实现</div>
                <pre class="code-block"><code class="language-python">"""
RAG完整实现：从文档到问答
- 文档加载与分割
- 向量嵌入
- 向量存储与检索
- LLM生成回答
"""
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import TextLoader, DirectoryLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.prompts import ChatPromptTemplate
from langchain.schema.runnable import RunnablePassthrough
from langchain.schema.output_parser import StrOutputParser
from typing import List, Tuple
import os

# 1. 文档加载
class DocumentLoader:
    """文档加载器"""
    
    @staticmethod
    def load_directory(path: str, glob_pattern: str = "**/*.txt") -> List:
        """加载目录下所有文档"""
        loader = DirectoryLoader(path, glob=glob_pattern, loader_cls=TextLoader)
        documents = loader.load()
        return documents
    
    @staticmethod
    def load_file(file_path: str) -> List:
        """加载单个文档"""
        loader = TextLoader(file_path, encoding="utf-8")
        return loader.load()

# 2. 文档分割
class TextSplitter:
    """文本分割器"""
    
    def __init__(self, chunk_size: int = 500, chunk_overlap: int = 50):
        self.splitter = RecursiveCharacterTextSplitter(
            chunk_size=chunk_size,
            chunk_overlap=chunk_overlap,
            separators=["\n\n", "\n", "。", "！", "？", "；", " ", ""]
        )
    
    def split(self, documents) -> List:
        """分割文档"""
        return self.splitter.split_documents(documents)

# 3. 向量存储
class VectorStore:
    """向量存储器"""
    
    def __init__(self, embedding_model=None):
        self.embedding = embedding_model or OpenAIEmbeddings()
        self.vectorstore = None
    
    def create(self, documents: List, save_path: str = None):
        """创建向量存储"""
        self.vectorstore = FAISS.from_documents(documents, self.embedding)
        
        if save_path:
            self.vectorstore.save_local(save_path)
            print(f"✅ 向量库已保存到: {save_path}")
    
    def load(self, path: str):
        """加载向量存储"""
        self.vectorstore = FAISS.load_local(path, self.embedding)
    
    def search(self, query: str, k: int = 4) -> List:
        """相似度检索"""
        if not self.vectorstore:
            raise ValueError("向量库未初始化")
        return self.vectorstore.similarity_search(query, k=k)
    
    def search_with_score(self, query: str, k: int = 4) -> List[Tuple]:
        """带分数的检索"""
        return self.vectorstore.similarity_search_with_score(query, k=k)

# 4. RAG链
class RAGChain:
    """RAG问答链"""
    
    def __init__(self, llm, vectorstore: VectorStore):
        self.llm = llm
        self.vectorstore = vectorstore
        
        # 提示词模板
        self.prompt_template = """基于以下上下文回答问题。如果上下文中没有相关信息，请说明你不知道。

上下文:
{context}

问题: {question}

回答:"""
        
        self.prompt = ChatPromptTemplate.from_template(self.prompt_template)
        self.chain = None
        self.build_chain()
    
    def build_chain(self):
        """构建RAG链"""
        retriever = self.vectorstore.vectorstore.as_retriever()
        
        self.chain = (
            {"context": retriever, "question": RunnablePassthrough()}
            | self.prompt
            | self.llm
            | StrOutputParser()
        )
    
    def invoke(self, question: str) -> str:
        """执行问答"""
        return self.chain.invoke(question)

# 5. 混合检索增强
class HybridRetriever:
    """混合检索器 - 向量+关键词"""
    
    def __init__(self, vectorstore: FAISS):
        self.vectorstore = vectorstore
        self.search_kwargs = {"k": 10}
    
    def search(self, query: str) -> List:
        """混合检索"""
        # 1. 向量检索
        vector_results = self.vectorstore.similarity_search(query, k=5)
        
        # 2. MMR检索（增加多样性）
        mmr_results = self.vectorstore.max_marginal_relevance_search(
            query, k=3, fetch_k=10
        )
        
        # 3. 合并去重
        seen = set()
        combined = []
        for doc in vector_results + mmr_results:
            doc_id = doc.metadata.get("source", "") + doc.page_content[:50]
            if doc_id not in seen:
                seen.add(doc_id)
                combined.append(doc)
        
        return combined[:4]


# 使用示例
def main():
    # 准备测试文档
    os.makedirs("docs", exist_ok=True)
    with open("docs/ai_intro.txt", "w", encoding="utf-8") as f:
        f.write("""人工智能(AI)是一门研究如何让机器具有智能的学科。
机器学习是AI的核心技术之一，让计算机从数据中学习规律。
深度学习是机器学习的一个分支，使用神经网络模型。
大语言模型(LLM)是深度学习的应用，可以理解和生成人类语言。
RAG技术可以增强LLM的知识，让AI回答私有知识库的问题。
""")
    
    with open("docs/rag_guide.txt", "w", encoding="utf-8") as f:
        f.write("""RAG(检索增强生成)是一种结合检索和生成的技术。
RAG的工作流程：加载文档 -> 分割文本 -> 向量化 -> 存储 -> 检索 -> 生成。
RAG的优点：1) 可以使用最新信息 2) 减少幻觉 3) 可以引用来源。
常用的向量数据库有FAISS、Chroma、Milvus、Pinecone等。
""")
    
    # 1. 加载文档
    print("📄 加载文档...")
    documents = DocumentLoader.load_directory("docs")
    print(f"  加载了 {len(documents)} 个文档")
    
    # 2. 分割文档
    print("✂️ 分割文档...")
    splitter = TextSplitter(chunk_size=100, chunk_overlap=20)
    chunks = splitter.split(documents)
    print(f"  分割成 {len(chunks)} 个块")
    
    # 3. 创建向量存储
    print("🔢 创建向量索引...")
    embedding = OpenAIEmbeddings()
    vectorstore = VectorStore(embedding)
    vectorstore.create(chunks, save_path="vectorstore")
    
    # 4. 测试检索
    print("\n🔍 测试检索...")
    results = vectorstore.search("什么是RAG？", k=2)
    for i, doc in enumerate(results):
        print(f"  结果{i+1}: {doc.page_content[:100]}...")
    
    # 5. 构建RAG链
    print("\n🤖 构建RAG问答链...")
    llm = ChatOpenAI(model="gpt-4", temperature=0)
    vectorstore.load("vectorstore")
    rag = RAGChain(llm, vectorstore)
    
    # 6. 执行问答
    questions = [
        "什么是RAG？",
        "人工智能和机器学习有什么关系？",
        "常用的向量数据库有哪些？"
    ]
    
    print("\n💬 RAG问答测试:")
    for q in questions:
        print(f"\n问题: {q}")
        answer = rag.invoke(q)
        print(f"回答: {answer}")

main()</code></pre>
            </div>

            <div class="card">
                <div class="card-header">代码说明</div>
                <div class="cards-grid" style="margin-top: 1rem;">
                    <div class="card" style="padding: 1rem;">
                        <h4 style="margin-bottom: 0.5rem;">📦 核心组件</h4>
                        <ul style="font-size: 0.85rem; padding-left: 1.2rem;">
                            <li>DocumentLoader - 文档加载</li>
                            <li>TextSplitter - 文本分割</li>
                            <li>VectorStore - 向量存储</li>
                            <li>RAGChain - 问答链</li>
                        </ul>
                    </div>
                    <div class="card" style="padding: 1rem;">
                        <h4 style="margin-bottom: 0.5rem;">🔄 工作流程</h4>
                        <ul style="font-size: 0.85rem; padding-left: 1.2rem;">
                            <li>加载文档</li>
                            <li>分割成chunks</li>
                            <li>向量化存储</li>
                            <li>检索+生成</li>
                        </ul>
                    </div>
                    <div class="card" style="padding: 1rem;">
                        <h4 style="margin-bottom: 0.5rem;">⚡ 优化策略</h4>
                        <ul style="font-size: 0.85rem; padding-left: 1.2rem;">
                            <li>调整chunk_size</li>
                            <li>使用MMR检索</li>
                            <li>混合检索</li>
                            <li>重排序</li>
                        </ul>
                    </div>
                </div>
            </div>

        </div>
    </section>
    <!-- Prism.js syntax highlighting -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-go.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-json.min.js"></script>
</body>
</html>