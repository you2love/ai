<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ä»£ç åº“ - AIæŠ€æœ¯å­¦ä¹ å¹³å°</title>
    <link rel="stylesheet" href="css/styles.css">
</head>
<body>
    <section class="section">
        <div class="container">
            <h2 class="section-title">ğŸ“š ä»£ç åº“</h2>
            <p class="section-subtitle">Python / Golang è°ƒç”¨å¤§æ¨¡å‹ API å®Œæ•´æŒ‡å—</p>

            <h3>Python OpenAI SDK å®Œæ•´åŠŸèƒ½</h3>

            <div class="card">
                <div class="card-header">1. åŸºç¡€è°ƒç”¨ - chat.completions</div>
                <pre class="code-block"><code class="language-python">from openai import OpenAI

client = OpenAI(
    api_key="your-api-key",
    base_url="https://api.openai.com/v1"  # å¯æ›¿æ¢ä¸ºå…¶ä»–å…¼å®¹ API
)

# åŸºç¡€å¯¹è¯
response = client.chat.completions.create(
    model="gpt-4o",
    messages=[
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šåŠ©æ‰‹"},
        {"role": "user", "content": "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"}
    ],
    temperature=0.7,
    max_tokens=1000,
    stream=False
)

print(response.choices[0].message.content)</code></pre>
            </div>

            <div class="card">
                <div class="card-header">2. æµå¼å“åº” - stream=True</div>
                <pre class="code-block"><code class="language-python">from openai import OpenAI

client = OpenAI(api_key="your-api-key")

stream = client.chat.completions.create(
    model="gpt-4o",
    messages=[{"role": "user", "content": "å†™ä¸€é¦–å…³äºæ˜¥å¤©çš„è¯—"}],
    stream=True
)

# é€å—æ¥æ”¶å“åº”
for chunk in stream:
    if chunk.choices[0].delta.content:
        content = chunk.choices[0].delta.content
        print(content, end="", flush=True)
print()</code></pre>
            </div>

            <div class="card">
                <div class="card-header">3. å‡½æ•°è°ƒç”¨ - function calling</div>
                <pre class="code-block"><code class="language-python">from openai import OpenAI
from pydantic import BaseModel
from typing import Optional

client = OpenAI(api_key="your-api-key")

# å®šä¹‰å‡½æ•°å·¥å…·
tools = [
    {
        "type": "function",
        "function": {
            "name": "get_weather",
            "description": "è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”ä¿¡æ¯",
            "parameters": {
                "type": "object",
                "properties": {
                    "city": {
                        "type": "string",
                        "description": "åŸå¸‚åç§°ï¼Œå¦‚åŒ—äº¬ã€ä¸Šæµ·"
                    }
                },
                "required": ["city"]
            }
        }
    }
]

# è°ƒç”¨æ¨¡å‹
response = client.chat.completions.create(
    model="gpt-4o",
    messages=[{"role": "user", "content": "åŒ—äº¬ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"}],
    tools=tools
)

# æ£€æŸ¥æ˜¯å¦æœ‰å‡½æ•°è°ƒç”¨
if response.choices[0].message.tool_calls:
    for tool_call in response.choices[0].message.tool_calls:
        function_name = tool_call.function.name
        arguments = tool_call.function.arguments
        print(f"éœ€è¦è°ƒç”¨å‡½æ•°: {function_name}")
        print(f"å‚æ•°: {arguments}")</code></pre>
            </div>

            <div class="card">
                <div class="card-header">4. ç»“æ„åŒ–è¾“å‡º - response_format</div>
                <pre class="code-block"><code class="language-python">from openai import OpenAI
from pydantic import BaseModel
from typing import List

client = OpenAI(api_key="your-api-key")

class WeatherInfo(BaseModel):
    city: str
    temperature: float
    humidity: int
    condition: str

# ä½¿ç”¨ JSON Schema æ¨¡å¼
response = client.chat.completions.create(
    model="gpt-4o",
    messages=[{"role": "user", "content": "ä¸Šæµ·ä»Šå¤©å¤©æ°”æ™´æœ—ï¼Œ25åº¦ï¼Œæ¹¿åº¦60%"}],
    response_format={
        "type": "json_object",
        "json_schema": {
            "name": "weather_info",
            "schema": {
                "type": "object",
                "properties": {
                    "city": {"type": "string"},
                    "temperature": {"type": "number"},
                    "humidity": {"type": "integer"},
                    "condition": {"type": "string"}
                },
                "required": ["city", "temperature", "humidity", "condition"]
            }
        }
    }
)

import json
result = json.loads(response.choices[0].message.content)
print(result)</code></pre>
            </div>

            <div class="card">
                <div class="card-header">5. åµŒå…¥å‘é‡ - embeddings</div>
                <pre class="code-block"><code class="language-python">from openai import OpenAI

client = OpenAI(api_key="your-api-key")

# ç”Ÿæˆæ–‡æœ¬åµŒå…¥å‘é‡
response = client.embeddings.create(
    model="text-embedding-3-small",
    input=[
        "äººå·¥æ™ºèƒ½æ”¹å˜ä¸–ç•Œ",
        "æœºå™¨å­¦ä¹ æ˜¯AIçš„æ ¸å¿ƒ",
        "æ·±åº¦å­¦ä¹ åº”ç”¨å¹¿æ³›"
    ],
    encoding_format="float"  # æˆ– "base64"
)

# è·å–åµŒå…¥å‘é‡
embeddings = response.data[0].embedding
print(f"å‘é‡ç»´åº¦: {len(embeddings)}")
print(f"ç›¸ä¼¼åº¦è®¡ç®—ç¤ºä¾‹:")
print(f"  å‘é‡1å‰5ä¸ªå€¼: {embeddings[:5]}")

# ç›¸ä¼¼åº¦è®¡ç®—
import numpy as np
vec1 = response.data[0].embedding
vec2 = response.data[1].embedding
cosine_sim = np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))
print(f"  å‘é‡1ä¸å‘é‡2ä½™å¼¦ç›¸ä¼¼åº¦: {cosine_sim:.4f}")</code></pre>
            </div>

            <div class="card">
                <div class="card-header">6. å›¾åƒç”Ÿæˆ - images.generate</div>
                <pre class="code-block"><code class="language-python">from openai import OpenAI

client = OpenAI(api_key="your-api-key")

# ç”Ÿæˆå›¾åƒ
response = client.images.generate(
    model="dall-e-3",
    prompt="ä¸€åªå¯çˆ±çš„å°çŒ«ååœ¨èŠ±å›­é‡Œï¼Œé˜³å…‰æ˜åªšï¼ŒçœŸå®é£æ ¼",
    size="1024x1024",
    quality="standard",
    n=1
)

image_url = response.data[0].url
print(f"ç”Ÿæˆçš„å›¾åƒ: {image_url}")

# ç¼–è¾‘å›¾åƒï¼ˆå±€éƒ¨ä¿®æ”¹ï¼‰
response = client.images.edit(
    model="dall-e-2",
    image=open("original.png", "rb"),
    mask=open("mask.png", "rb"),
    prompt="ç»™å°çŒ«æˆ´ä¸Šå¸½å­",
    n=1,
    size="1024x1024"
)

# å›¾åƒå˜ä½“
response = client.images.create_variation(
    image=open("original.png", "rb"),
    n=2,
    size="1024x1024"
)</code></pre>
            </div>

            <div class="card">
                <div class="card-header">7. éŸ³é¢‘å¤„ç† - audio</div>
                <pre class="code-block"><code class="language-python">from openai import OpenAI

client = OpenAI(api_key="your-api-key")

# è¯­éŸ³è½¬æ–‡å­— (Whisper)
audio_file = open("speech.mp3", "rb")
transcript = client.audio.transcriptions.create(
    model="whisper-1",
    file=audio_file
)
print(transcript.text)

# æ–‡å­—è½¬è¯­éŸ³ (TTS)
response = client.audio.speech.create(
    model="tts-1",
    voice="alloy",  # alloy, echo, fable, onyx, nova, shimmer
    input="ä½ å¥½ï¼Œè¿™æ˜¯ä¸€ä¸ªè¯­éŸ³åˆæˆçš„ç¤ºä¾‹"
)

response.stream_to_file("output.mp3")

# ç¿»è¯‘éŸ³é¢‘ï¼ˆ Whisper æ”¯æŒå¤šè¯­è¨€è½¬è‹±æ–‡ï¼‰
audio_file = open("chinese_speech.mp3", "rb")
translation = client.audio.translations.create(
    model="whisper-1",
    file=audio_file
)
print(translation.text)</code></pre>
            </div>

            <div class="card">
                <div class="card-header">8. æ¨¡å‹åˆ—è¡¨ä¸ä¿¡æ¯ - models.list/retrieve</div>
                <pre class="code-block"><code class="language-python">from openai import OpenAI

client = OpenAI(api_key="your-api-key")

# åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ¨¡å‹
models = client.models.list()
print("å¯ç”¨æ¨¡å‹åˆ—è¡¨ï¼ˆå‰10ä¸ªï¼‰:")
for model in models.data[:10]:
    print(f"  - {model.id} (åˆ›å»ºäº: {model.created})")

# è·å–ç‰¹å®šæ¨¡å‹ä¿¡æ¯
model = client.models.retrieve("gpt-4o")
print(f"\næ¨¡å‹è¯¦æƒ…:")
print(f"  ID: {model.id}")
print(f"  æ‹¥æœ‰è€…: {model.owned_by}")
print(f"  æ˜¯å¦æ”¯æŒç”Ÿæˆ: {model.capabilities['can_generate']}")

# æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ”¯æŒæŸåŠŸèƒ½
print(f"  æ”¯æŒè§†è§‰: {model.capabilities.get('vision', False)}")</code></pre>
            </div>

            <div class="card">
                <div class="card-header">9. å¾®è°ƒç®¡ç† - fine_tuning</div>
                <pre class="code-block"><code class="language-python">from openai import OpenAI

client = OpenAI(api_key="your-api-key")

# åˆ›å»ºå¾®è°ƒä»»åŠ¡
job = client.fine_tuning.jobs.create(
    training_file="file-xxx",  # ä¸Šä¼ çš„è®­ç»ƒæ–‡ä»¶ ID
    model="gpt-3.5-turbo",
    hyperparameters={
        "n_epochs": 3,
        "batch_size": 1,
        "learning_rate_multiplier": 0.1
    }
)
print(f"å¾®è°ƒä»»åŠ¡ ID: {job.id}")

# æŸ¥è¯¢å¾®è°ƒçŠ¶æ€
job = client.fine_tuning.jobs.retrieve(job.id)
print(f"çŠ¶æ€: {job.status}")  # queued, running, succeeded, failed

# åˆ—å‡ºæ‰€æœ‰å¾®è°ƒä»»åŠ¡
jobs = client.fine_tuning.jobs.list(limit=10)
for job in jobs.data:
    print(f"  - {job.id}: {job.status}")

# å–æ¶ˆå¾®è°ƒä»»åŠ¡
# client.fine_tuning.jobs.cancel(job.id)

# åˆ é™¤å¾®è°ƒåçš„æ¨¡å‹
# client.models.delete("ft:gpt-3.5-turbo:xxx")</code></pre>
            </div>

            <div class="card">
                <div class="card-header">10. æ–‡ä»¶ç®¡ç† - files</div>
                <pre class="code-block"><code class="language-python">from openai import OpenAI

client = OpenAI(api_key="your-api-key")

# ä¸Šä¼ æ–‡ä»¶ï¼ˆç”¨äºå¾®è°ƒæˆ–çŸ¥è¯†åº“ï¼‰
file = client.files.create(
    file=open("training_data.jsonl", "rb"),
    purpose="fine-tune"
)
print(f"æ–‡ä»¶ ID: {file.id}")

# åˆ—å‡ºå·²ä¸Šä¼ æ–‡ä»¶
files = client.files.list(purpose="fine-tune")
for f in files.data:
    print(f"  - {f.id}: {f.filename} ({f.bytes} bytes)")

# è·å–æ–‡ä»¶å†…å®¹
content = client.files.content("file-xxx")
print(content.text)

# åˆ é™¤æ–‡ä»¶
# client.files.delete("file-xxx")</code></pre>
            </div>

            <div class="card">
                <div class="card-header">11. åŠ©æ‰‹ API - assistants</div>
                <pre class="code-block"><code class="language-python">from openai import OpenAI

client = OpenAI(api_key="your-api-key")

# åˆ›å»ºåŠ©æ‰‹
assistant = client.beta.assistants.create(
    name="æ•°å­¦è€å¸ˆ",
    instructions="ä½ æ˜¯ä¸€ä¸ªæ•°å­¦è€å¸ˆï¼Œæ“…é•¿è§£é‡Šæ•°å­¦æ¦‚å¿µå’Œè§£é¢˜",
    model="gpt-4o",
    tools=[{"type": "code_interpreter"}]  # æ”¯æŒä»£ç è§£é‡Šå™¨ã€æ–‡ä»¶æœç´¢
)
print(f"åŠ©æ‰‹ ID: {assistant.id}")

# åˆ›å»ºçº¿ç¨‹
thread = client.beta.threads.create(
    messages=[
        {
            "role": "user",
            "content": "è¯·è§£é‡Šä¸€ä¸‹å‹¾è‚¡å®šç†"
        }
    ]
)

# æ·»åŠ æ¶ˆæ¯å¹¶è¿è¡Œ
message = client.beta.threads.messages.create(
    thread_id=thread.id,
    role="user",
    content="å·²çŸ¥ç›´è§’ä¸‰è§’å½¢ä¸¤æ¡ç›´è§’è¾¹ä¸º3å’Œ4ï¼Œæ±‚æ–œè¾¹é•¿åº¦"
)

run = client.beta.threads.runs.create(
    thread_id=thread.id,
    assistant_id=assistant.id
)

# è·å–è¿è¡Œç»“æœ
run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)
while run.status == "completed":
    messages = client.beta.threads.messages.list(thread_id=thread.id)
    print(messages.data[0].content[0].text.value)
    break</code></pre>
            </div>

            <div class="card">
                <div class="card-header">12. æ‰¹å¤„ç† API - batch</div>
                <pre class="code-block"><code class="language-python">from openai import OpenAI

client = OpenAI(api_key="your-api-key")

# åˆ›å»ºæ‰¹å¤„ç†ä»»åŠ¡
batch_job = client.beta.batch.create(
    input_file_id="file-xxx",  # JSONL æ ¼å¼æ–‡ä»¶
    endpoint="/v1/chat/completions",
    completion_window="24h",
    metadata={
        "description": "æ¯æ—¥æ•°æ®å¤„ç†"
    }
)
print(f"æ‰¹å¤„ç† ID: {batch_job.id}")

# æŸ¥è¯¢æ‰¹å¤„ç†çŠ¶æ€
batch_job = client.beta.batch.retrieve(batch_job.id)
print(f"çŠ¶æ€: {batch_job.status}")  # validating, in_progress, completed, failed

# åˆ—å‡ºæ‰€æœ‰æ‰¹å¤„ç†ä»»åŠ¡
batches = client.beta.batch.list()
for batch in batches.data:
    print(f"  - {batch.id}: {batch.status}")</code></pre>
            </div>

            <div class="card">
                <div class="card-header">13. å¼‚æ­¥ä½œä¸š - vector storesï¼ˆçŸ¥è¯†åº“ï¼‰</div>
                <pre class="code-block"><code class="language-python">from openai import OpenAI

client = OpenAI(api_key="your-api-key")

# åˆ›å»ºå‘é‡å­˜å‚¨ï¼ˆçŸ¥è¯†åº“ï¼‰
vector_store = client.beta.vector_stores.create(
    name="äº§å“æ–‡æ¡£",
    file_ids=["file-xxx", "file-yyy"]  # å·²ä¸Šä¼ çš„æ–‡ä»¶
)
print(f"å‘é‡å­˜å‚¨ ID: {vector_store.id}")

# æ·»åŠ æ–‡ä»¶åˆ°å‘é‡å­˜å‚¨
client.beta.vector_stores.files.create(
    vector_store_id=vector_store.id,
    file_id="file-zzz"
)

# ä½¿ç”¨å‘é‡å­˜å‚¨è¿›è¡Œé—®ç­”
assistant = client.beta.assistants.create(
    name="äº§å“åŠ©æ‰‹",
    model="gpt-4o",
    tool_resources={
        "file_search": {
            "vector_store_ids": [vector_store.id]
        }
    }
)

# å‘é‡å­˜å‚¨åˆ—è¡¨
stores = client.beta.vector_stores.list()
for store in stores.data:
    print(f"  - {store.name}: {store.file_counts}")</code></pre>
            </div>

            <h3>Golang OpenAI SDK å®Œæ•´åŠŸèƒ½</h3>

            <div class="card">
                <div class="card-header">1. åŸºç¡€è°ƒç”¨</div>
                <pre class="code-block"><code class="language-go">package main

import (
    "context"
    "fmt"
    "github.com/openai/openai-go"
)

func main() {
    client := openai.NewClient(
        openai.WithAPIKey("your-api-key"),
        // openai.WithBaseURL("https://api.openai.com/v1"),
    )

    // åŸºç¡€å¯¹è¯
    resp, err := client.Chat.Completions.New(context.TODO(), openai.ChatCompletionNewParams{
        Model:    openai.F("gpt-4o"),
        Messages: []openai.ChatCompletionMessageParamUnion{
            openai.ChatCompletionSystemMessageParam{
                Content: openai.ChatCompletionSystemMessageContent{
                    Text: openai.String("ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šåŠ©æ‰‹"),
                },
            },
            openai.ChatCompletionUserMessageParam{
                Content: openai.ChatCompletionUserMessageContent{
                    Text: openai.String("ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"),
                },
            },
        },
        Temperature: openai.Float(0.7),
        MaxTokens:   openai.Int(1000),
    })

    if err != nil {
        panic(err)
    }

    fmt.Println(resp.Choices[0].Message.Content)
}</code></pre>
            </div>

            <div class="card">
                <div class="card-header">2. æµå¼å“åº”</div>
                <pre class="code-block"><code class="language-go">package main

import (
    "context"
    "fmt"
    "github.com/openai/openai-go"
    "github.com/openai/openai-go/option"
)

func main() {
    client := openai.NewClient(option.WithAPIKey("your-api-key"))

    stream := client.Chat.Completions.NewStreaming(context.TODO(), openai.ChatCompletionNewParams{
        Model:    openai.F("gpt-4o"),
        Messages: []openai.ChatCompletionMessageParamUnion{
            openai.ChatCompletionUserMessageParam{
                Content: openai.ChatCompletionUserMessageContent{
                    Text: openai.String("è®²ä¸€ä¸ªç¬‘è¯"),
                },
            },
        },
    })

    for {
        chunk, err := stream.Recv()
        if err != nil {
            break
        }

        if content := chunk.Choices[0].Delta.Content; content != "" {
            fmt.Print(content)
        }
    }
    fmt.Println()
}</code></pre>
            </div>

            <div class="card">
                <div class="card-header">3. å‡½æ•°è°ƒç”¨</div>
                <pre class="code-block"><code class="language-go">package main

import (
    "context"
    "encoding/json"
    "fmt"
    "github.com/openai/openai-go"
)

type WeatherParams struct {
    City string `json:"city"`
}

func main() {
    client := openai.NewClient(openai.WithAPIKey("your-api-key"))

    tools := []openai.ChatCompletionToolParam{
        {
            Type: openai.F("function"),
            Function: openai.FunctionDefinitionParam{
                Name:        openai.String("get_weather"),
                Description: openai.String("è·å–åŸå¸‚å¤©æ°”"),
                Parameters: openai.F(map[string]any{
                    "type": "object",
                    "properties": map[string]any{
                        "city": map[string]any{
                            "type":        "string",
                            "description": "åŸå¸‚åç§°",
                        },
                    },
                    "required": []string{"city"},
                }),
            },
        },
    }

    resp, err := client.Chat.Completions.New(context.TODO(), openai.ChatCompletionNewParams{
        Model:    openai.F("gpt-4o"),
        Messages: []openai.ChatCompletionMessageParamUnion{
            openai.ChatCompletionUserMessageParam{
                Content: openai.ChatCompletionUserMessageContent{
                    Text: openai.String("åŒ—äº¬å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"),
                },
            },
        },
        Tools: openai.F(tools),
    })

    if err != nil {
        panic(err)
    }

    for _, choice := range resp.Choices {
        if choice.Message.ToolCalls != nil {
            for _, call := range choice.Message.ToolCalls {
                fmt.Printf("è°ƒç”¨å‡½æ•°: %s\n", call.Function.Name)

                var params WeatherParams
                json.Unmarshal([]byte(call.Function.Arguments), &params)
                fmt.Printf("å‚æ•°: %+v\n", params)
            }
        }
    }
}</code></pre>
            </div>

            <div class="card">
                <div class="card-header">4. åµŒå…¥å‘é‡</div>
                <pre class="code-block"><code class="language-go">package main

import (
    "context"
    "fmt"
    "github.com/openai/openai-go"
)

func main() {
    client := openai.NewClient(openai.WithAPIKey("your-api-key"))

    resp, err := client.Embeddings.New(context.TODO(), openai.EmbeddingNewParams{
        Model: openai.F("text-embedding-3-small"),
        Input: []string{
            "äººå·¥æ™ºèƒ½æ”¹å˜ä¸–ç•Œ",
            "æœºå™¨å­¦ä¹ æ˜¯AIçš„æ ¸å¿ƒ",
            "æ·±åº¦å­¦ä¹ åº”ç”¨å¹¿æ³›",
        },
    })

    if err != nil {
        panic(err)
    }

    for i, data := range resp.Data {
        fmt.Printf("æ–‡æœ¬ %d å‘é‡ç»´åº¦: %d\n", i+1, len(data.Embedding))
    }

    // è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
    vec1 := resp.Data[0].Embedding
    vec2 := resp.Data[1].Embedding

    var dot, norm1, norm2 float64
    for i := range vec1 {
        dot += vec1[i] * vec2[i]
        norm1 += vec1[i] * vec1[i]
        norm2 += vec2[i] * vec2[i]
    }

    similarity := dot / (sqrt(norm1) * sqrt(norm2))
    fmt.Printf("ä½™å¼¦ç›¸ä¼¼åº¦: %.4f\n", similarity)
}</code></pre>
            </div>

            <div class="card">
                <div class="card-header">5. å›¾åƒç”Ÿæˆ</div>
                <pre class="code-block"><code class="language-go">package main

import (
    "context"
    "fmt"
    "github.com/openai/openai-go"
)

func main() {
    client := openai.NewClient(openai.WithAPIKey("your-api-key"))

    // ç”Ÿæˆå›¾åƒ
    resp, err := client.Images.Generate(context.TODO(), openai.ImageGenerateParams{
        Model:   openai.F("dall-e-3"),
        Prompt: openai.String("ä¸€åªå¯çˆ±çš„å°çŒ«ååœ¨èŠ±å›­é‡Œï¼Œé˜³å…‰æ˜åªš"),
        Size:    openai.F("1024x1024"),
        Quality: openai.F("standard"),
        N:       openai.Int(1),
    })

    if err != nil {
        panic(err)
    }

    fmt.Printf("ç”Ÿæˆçš„å›¾åƒ: %s\n", resp.Data[0].URL)
}</code></pre>
            </div>

            <div class="card">
                <div class="card-header">6. è¯­éŸ³å¤„ç†</div>
                <pre class="code-block"><code class="language-go">package main

import (
    "context"
    "fmt"
    "os"
    "github.com/openai/openai-go"
)

func main() {
    client := openai.NewClient(openai.WithAPIKey("your-api-key"))

    // è¯­éŸ³è½¬æ–‡å­— (Whisper)
    file, _ := os.Open("speech.mp3")
    defer file.Close()

    resp, err := client.Audio.Transcriptions.New(context.TODO(), openai.AudioTranscriptionNewParams{
        Model:    openai.F("whisper-1"),
        File:     file,
        Filename: openai.String("speech.mp3"),
    })

    if err != nil {
        panic(err)
    }

    fmt.Printf("è½¬å†™ç»“æœ: %s\n", resp.Text)

    // æ–‡å­—è½¬è¯­éŸ³ (TTS)
    speech, err := client.Audio.Speech.New(context.TODO(), openai.AudioSpeechNewParams{
        Model:  openai.F("tts-1"),
        Voice:  openai.F("alloy"),
        Input:  openai.String("ä½ å¥½ï¼Œè¿™æ˜¯è¯­éŸ³åˆæˆçš„ç¤ºä¾‹"),
    })

    if err != nil {
        panic(err)
    }

    speech.WriteToFile("output.mp3")
}</code></pre>
            </div>

            <div class="card">
                <div class="card-header">7. åŠ©æ‰‹ API</div>
                <pre class="code-block"><code class="language-go">package main

import (
    "context"
    "fmt"
    "github.com/openai/openai-go"
)

func main() {
    client := openai.NewClient(openai.WithAPIKey("your-api-key"))

    // åˆ›å»ºåŠ©æ‰‹
    assistant, err := client.Beta.Assistants.New(context.TODO(), openai.AssistantNewParams{
        Name:     openai.String("æ•°å­¦è€å¸ˆ"),
        Model:    openai.F("gpt-4o"),
        Instructions: openai.String("ä½ æ˜¯ä¸€ä¸ªæ•°å­¦è€å¸ˆ"),
        Tools: []openai.AssistantToolParam{
            {Type: openai.F(openai.AssistantToolTypeCodeInterpreter)},
        },
    })

    if err != nil {
        panic(err)
    }
    fmt.Printf("åŠ©æ‰‹ ID: %s\n", assistant.ID)

    // åˆ›å»ºçº¿ç¨‹
    thread, _ := client.Beta.Threads.New(context.TODO(), openai.ThreadNewParams{})

    // æ·»åŠ æ¶ˆæ¯
    _, _ = client.Beta.Threads.Messages.New(context.TODO(), openai.ThreadMessageNewParams{
        ThreadID: openai.String(thread.ID),
        Role:     openai.F(openai.ThreadMessageRoleUser),
        Content: openai.F([]openai.ThreadMessageNewParamsContentUnion{
            openai.ThreadMessageNewParamsContent{
                Text: openai.ThreadMessageTextContentParam{
                    Text: openai.String("å‹¾è‚¡å®šç†æ˜¯ä»€ä¹ˆï¼Ÿ"),
                },
            },
        }),
    })

    // è¿è¡ŒåŠ©æ‰‹
    run, _ := client.Beta.Threads.Runs.New(context.TODO(), openai.ThreadRunNewParams{
        ThreadID:    openai.String(thread.ID),
        AssistantID: openai.String(assistant.ID),
    })

    // è·å–è¿è¡Œç»“æœ
    run, _ = client.Beta.Threads.Runs.Get(context.TODO(), thread.ID, run.ID)
    fmt.Printf("è¿è¡ŒçŠ¶æ€: %s\n", run.Status)
}</code></pre>
            </div>

            <h3>å®ç”¨ä»£ç ç‰‡æ®µ</h3>

            <div class="card">
                <div class="card-header">å¹¶å‘è°ƒç”¨å¤šä¸ªæ¨¡å‹</div>
                <pre class="code-block"><code class="language-python">import asyncio
from openai import AsyncOpenAI

client = AsyncOpenAI(api_key="your-api-key")

async def call_model(model, prompt):
    response = await client.chat.completions.create(
        model=model,
        messages=[{"role": "user", "content": prompt}]
    )
    return model, response.choices[0].message.content

async def main():
    prompts = [
        ("gpt-4o", "ç”¨ä¸€å¥è¯ä»‹ç»AI"),
        ("claude-3-5-sonnet", "ç”¨ä¸€å¥è¯ä»‹ç»AI"),
        ("gemini-1.5-pro", "ç”¨ä¸€å¥è¯ä»‹ç»AI"),
    ]

    tasks = [call_model(model, prompt) for model, prompt in prompts]
    results = await asyncio.gather(*tasks)

    for model, response in results:
        print(f"{model}: {response}")

asyncio.run(main())</code></pre>
            </div>

            <div class="card">
                <div class="card-header">é€Ÿç‡é™åˆ¶å¤„ç†</div>
                <pre class="code-block"><code class="language-python">import time
from openai import OpenAI, RateLimitError, APIError

client = OpenAI(api_key="your-api-key")

def make_request_with_retry(prompt, max_retries=3):
    for attempt in range(max_retries):
        try:
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": prompt}]
            )
            return response.choices[0].message.content

        except RateLimitError as e:
            wait_time = (2 ** attempt) * 10  # æŒ‡æ•°é€€é¿
            print(f"é€Ÿç‡é™åˆ¶ï¼Œç­‰å¾… {wait_time} ç§’...")
            time.sleep(wait_time)

        except APIError as e:
            if e.status_code >= 500:
                wait_time = (2 ** attempt) * 5
                print(f"æœåŠ¡å™¨é”™è¯¯ï¼Œç­‰å¾… {wait_time} ç§’...")
                time.sleep(wait_time)
            else:
                raise e

    raise Exception(f"é‡è¯• {max_retries} æ¬¡åä»å¤±è´¥")</code></pre>
            </div>

            <div class="card">
                <div class="card-header">Token è®¡æ•°ä¸æˆæœ¬è®¡ç®—</div>
                <pre class="code-block"><code class="language-python">import tiktoken
from openai import OpenAI

client = OpenAI(api_key="your-api-key")

PRICING = {
    "gpt-4o": {"input": 5.0, "output": 15.0},      # æ¯ç™¾ä¸‡ token
    "gpt-4o-mini": {"input": 0.15, "output": 0.6},
    "gpt-3.5-turbo": {"input": 0.5, "output": 1.5},
}

def count_tokens(text, model="gpt-4o"):
    encoder = tiktoken.encoding_for_model(model)
    return len(encoder.encode(text))

def estimate_cost(prompt, response, model="gpt-4o"):
    prompt_tokens = count_tokens(prompt, model)
    completion_tokens = count_tokens(response, model)
    pricing = PRICING.get(model, {"input": 0, "output": 0})

    input_cost = (prompt_tokens / 1_000_000) * pricing["input"]
    output_cost = (completion_tokens / 1_000_000) * pricing["output"]

    return {
        "prompt_tokens": prompt_tokens,
        "completion_tokens": completion_tokens,
        "total_tokens": prompt_tokens + completion_tokens,
        "cost": input_cost + output_cost
    }

# ä½¿ç”¨ç¤ºä¾‹
prompt = "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"
response = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[{"role": "user", "content": prompt}]
)
content = response.choices[0].message.content
cost_info = estimate_cost(prompt, content, "gpt-4o-mini")
print(f"æ¶ˆè€— Token: {cost_info['total_tokens']}")
print(f"é¢„ä¼°æˆæœ¬: ${cost_info['cost']:.6f}")</code></pre>
            </div>

            <h3>å›½äº§æ¨¡å‹ API å…¼å®¹è°ƒç”¨</h3>

            <div class="card">
                <div class="card-header">é˜¿é‡Œé€šä¹‰åƒé—®</div>
                <pre class="code-block"><code class="language-python">from openai import OpenAI

# é€šä¹‰åƒé—® API
client = OpenAI(
    api_key="your-dashscope-api-key",
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
)

# ä½¿ç”¨é€šä¹‰åƒé—®æ¨¡å‹
response = client.chat.completions.create(
    model="qwen-turbo",  # qwen-turbo, qwen-plus, qwen-max
    messages=[{"role": "user", "content": "ä½ å¥½"}],
    max_tokens=1000
)

print(response.choices[0].message.content)

# è°ƒç”¨é€šä¹‰åƒé—®çš„è”ç½‘æœç´¢åŠŸèƒ½
response = client.chat.completions.create(
    model="qwen-turbo",
    messages=[{"role": "user", "content": "ä»Šå¤©åŒ—äº¬çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"}],
    extra_body={
        "enable_search": True  # å¯ç”¨è”ç½‘æœç´¢
    }
)</code></pre>
            </div>

            <div class="card">
                <div class="card-header">ç™¾åº¦æ–‡å¿ƒä¸€è¨€</div>
                <pre class="code-block"><code class="language-python">from openai import OpenAI

# æ–‡å¿ƒä¸€è¨€ API
client = OpenAI(
    api_key="your-wenxin-api-key",
    base_url="https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/chat"
)

# æ³¨æ„ï¼šç™¾åº¦éœ€è¦é¢å¤–é…ç½® access_token
import requests

# è·å– access_token
def get_baidu_token(api_key, secret_key):
    url = "https://aip.baidubce.com/oauth/2.0/token"
    params = {
        "grant_type": "client_credentials",
        "client_id": api_key,
        "client_secret": secret_key
    }
    response = requests.post(url, params=params)
    return response.json().get("access_token")

# è°ƒç”¨æ–‡å¿ƒä¸€è¨€
access_token = get_baidu_token("your-api-key", "your-secret-key")
client = OpenAI(
    api_key=access_token,
    base_url="https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/chat"
)

response = client.chat.completions.create(
    model="ernie-4.5-8k",
    messages=[{"role": "user", "content": "ä½ å¥½"}]
)</code></pre>
            </div>

            <div class="card">
                <div class="card-header">æ™ºè°±æ¸…è¨€</div>
                <pre class="code-block"><code class="language-python">from openai import OpenAI

# æ™ºè°±æ¸…è¨€ API
client = OpenAI(
    api_key="your-zhipu-api-key",
    base_url="https://open.bigmodel.cn/api/paas/v4"
)

# ä½¿ç”¨æ™ºè°± GLM ç³»åˆ—æ¨¡å‹
response = client.chat.completions.create(
    model="glm-4",  # glm-4, glm-4v, glm-3-turbo
    messages=[
        {"role": "system", "content": "ä½ æ˜¯æ™ºè°±æ¸…è¨€ï¼Œä¸€ä¸ªä¹äºåŠ©äººçš„åŠ©æ‰‹"},
        {"role": "user", "content": "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±"}
    ],
    temperature=0.7,
    max_tokens=2000
)

print(response.choices[0].message.content)</code></pre>
            </div>

            <div class="card">
                <div class="card-header">DeepSeek</div>
                <pre class="code-block"><code class="language-python">from openai import OpenAI

# DeepSeek API
client = OpenAI(
    api_key="your-deepseek-api-key",
    base_url="https://api.deepseek.com"
)

# ä½¿ç”¨ DeepSeek æ¨¡å‹
response = client.chat.completions.create(
    model="deepseek-chat",  # deepseek-chat, deepseek-reasoner
    messages=[{"role": "user", "content": "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ DeepSeek"}],
    max_tokens=4096,
    temperature=0.7
)

print(response.choices[0].message.content)

# DeepSeek Reasonerï¼ˆæ¨ç†å¢å¼ºæ¨¡å‹ï¼‰
response = client.chat.completions.create(
    model="deepseek-reasoner",
    messages=[{"role": "user", "content": "å¦‚æœa+b=10ï¼Œa-b=2ï¼Œé‚£ä¹ˆaå’Œbåˆ†åˆ«æ˜¯å¤šå°‘ï¼Ÿ"}]
)

print(f"æ¨ç†ç»“æœ: {response.choices[0].message.content}")
print(f"æ¨ç†è¿‡ç¨‹: {response.choices[0].message.reasoning_content}")</code></pre>
            </div>

            <div class="card">
                <div class="card-header">è…¾è®¯æ··å…ƒ</div>
                <pre class="code-block"><code class="language-python">from openai import OpenAI

# è…¾è®¯æ··å…ƒ API
client = OpenAI(
    api_key="your-hunyuan-api-key",
    base_url="https://hunyuan.cn-shanghai..tencentcloudapi.com"
)

# ä½¿ç”¨æ··å…ƒæ¨¡å‹
response = client.chat.completions.create(
    model="hunyuan",  # hunyuan, hunyuan-vision
    messages=[{"role": "user", "content": "ä½ å¥½"}],
    temperature=0.7,
    max_tokens=2048
)

print(response.choices[0].message.content)</code></pre>
            </div>

        </div>
    </section>

    <script src="js/main.js"></script>
</body>
</html>